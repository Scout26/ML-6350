# -*- coding: utf-8 -*-
"""3(d)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ehiARRgTYRO5_tOIg0cL29lFa8JwU3S
"""

import numpy as np
import pandas as pd
from scipy.spatial.distance import cdist

# Load the training and testing datasets into the dataframe
train_data = pd.read_csv('train.csv', header=None)
test_data = pd.read_csv('test.csv', header=None)

# Extract features and labels from datasets
features_train = train_data.iloc[:, :-1].values
labels_train = train_data.iloc[:, -1].values
features_test = test_data.iloc[:, :-1].values
labels_test = test_data.iloc[:, -1].values

# Transform label to 1 and -1
labels_train = np.where(labels_train == 0, -1, 1)
labels_test = np.where(labels_test == 0, -1, 1)

# Given parameters
gamma_options = [0.1, 0.5, 1, 5, 100]

# Calculating pairwise squared distances
def compute_gaussian_kernel(X1, X2, gamma_value):
    squared_distances = cdist(X1, X2, 'sqeuclidean')
    return np.exp(-squared_distances / gamma_value)

# Function for Kernel Based Perceptron
def kernel_based_perceptron(train_features, train_labels, test_features, test_labels, gamma_value):
    num_samples = train_features.shape[0]
    mistake_counts = np.zeros(num_samples)
    kernel_train = compute_gaussian_kernel(train_features, train_features, gamma_value)

    # Training Data
    for epoch in range(10):
        for idx in range(num_samples):
            if np.sign(np.sum(mistake_counts * train_labels * kernel_train[:, idx])) != train_labels[idx]:
                mistake_counts[idx] += 1

    # Calculate prediction for training data
    predictions_train = np.sign(np.sum(mistake_counts * train_labels * kernel_train, axis=1))
    error_train = np.mean(predictions_train != train_labels)

    # Calculate prediction for test data
    kernel_test = compute_gaussian_kernel(test_features, train_features, gamma_value)
    predictions_test = np.sign(np.sum(mistake_counts * train_labels * kernel_test, axis=1))
    error_test = np.mean(predictions_test != test_labels)

    return error_train, error_test

# PrepaWriting the results list for tabular storage
results = []

# Combining the results
for gamma_value in gamma_options:
    train_err, test_err = kernel_based_perceptron(features_train, labels_train, features_test, labels_test, gamma_value)
    results.append([gamma_value, train_err, test_err])

# Convert the results  to a DataFrame
results_df = pd.DataFrame(results, columns=["Gamma Value", "Training Error", "Test Error"])

# Writing the results in Table format for better representation.
print(results_df.to_string(index=False, float_format="{:.4f}".format))

