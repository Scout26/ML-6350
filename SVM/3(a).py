# -*- coding: utf-8 -*-
"""3(a)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cr7ntHt2aPFNCdYj7OKIyKbQTU5mh-4G
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import minimize

# Load training and testing datasets into dataframe
training_data = pd.read_csv('train.csv', header=None)
testing_data = pd.read_csv('test.csv', header=None)

# Extract features and labels
features_train = training_data.iloc[:, :-1].values
labels_train = training_data.iloc[:, -1].values
features_test = testing_data.iloc[:, :-1].values
labels_test = testing_data.iloc[:, -1].values

# Convert labels to {-1, 1}
labels_train = np.where(labels_train == 0, -1, 1)
labels_test = np.where(labels_test == 0, -1, 1)

# Regularization parameter values( C value)
regularization_values = [100/873, 500/873, 700/873]

# Objective function for dual SVM
def svm_dual_objective(alphas, X, y):
    y = y.reshape(-1, 1)
    kernel_matrix = np.dot(X, X.T) * (y @ y.T)
    return 0.5 * alphas @ kernel_matrix @ alphas - np.sum(alphas)

# Constraint function: sum(alpha_i * y_i) = 0
def constraint_eq(alphas, y):
    return np.dot(alphas, y)

# Train SVM for each value of regularization parameter
for reg_param in regularization_values:
    num_samples = features_train.shape[0]

    # Initial alpha value
    alpha_initial = np.zeros(num_samples)

    # Constraints and bounds for optimization
    constraints = ({'type': 'eq', 'fun': constraint_eq, 'args': (labels_train,)})
    bounds = [(0, reg_param) for _ in range(num_samples)]

    # Optimize dual problem using SLSQP which aslo helps in faster data processing.
    optimization_result = minimize(
        svm_dual_objective,
        alpha_initial,
        args=(features_train, labels_train),
        method='SLSQP',
        bounds=bounds,
        constraints=constraints
    )
    optimized_alphas = optimization_result.x

    # Calculate weights
    weight_vector = np.sum((optimized_alphas * labels_train)[:, None] * features_train, axis=0)

    # Calculate bias using support vectors
    support_vector_mask = (optimized_alphas > 1e-5) & (optimized_alphas < reg_param - 1e-5)
    bias_term = np.mean(
        labels_train[support_vector_mask] - np.dot(features_train[support_vector_mask], weight_vector)
    )

    # Print weights and bias
    print(f"For value of C = {reg_param:.4f}: Weights = {weight_vector}, Bias = {bias_term:.4f}")

    # Calculate training and testing errors
    train_pred = np.sign(np.dot(features_train, weight_vector) + bias_term)
    test_pred = np.sign(np.dot(features_test, weight_vector) + bias_term)
    training_error = np.mean(train_pred != labels_train)
    testing_error = np.mean(test_pred != labels_test)

    # Display the fnal values:
    print(f"For value of C = {reg_param:.4f}: Training Error is  = {training_error:.4f}, Testing Error is = {testing_error:.4f}")

