{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O62T8VxJVlUs",
        "outputId": "1989ae26-e411-4cea-9603-91b2ce13c994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final averaged weight vector: [-46.60072831 -29.06735968 -30.14480192  -8.94214493]\n",
            "Test Error Rate: 0.014\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Loading training and testing datasets into train and test variables.\n",
        "train_data = pd.read_csv('train.csv', header=None)\n",
        "test_data = pd.read_csv('test.csv', header=None)\n",
        "\n",
        "# Separate features and target labels for training and testing datasets\n",
        "X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values\n",
        "X_test, y_test = test_data.iloc[:, :-1].values, test_data.iloc[:, -1].values\n",
        "\n",
        "# Convert labels: map 0 to -1, keep 1 as is, for compatibility with Perceptron training\n",
        "y_train = np.where(y_train == 0, -1, 1)\n",
        "y_test = np.where(y_test == 0, -1, 1)\n",
        "\n",
        "# Function to train using the Average Perceptron method\n",
        "def train_avg_perceptron(X, y, num_epochs=10):\n",
        "    sample_count, feature_count = X.shape\n",
        "    weights = np.zeros(feature_count)  # Initialize the weight vector\n",
        "    bias = 0\n",
        "    sum_weights = np.zeros(feature_count)  # Track cumulative weights for averaging\n",
        "    sum_bias = 0\n",
        "\n",
        "    # Iterate over multiple epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        for i in range(sample_count):\n",
        "            # Check if misclassified\n",
        "            if y[i] * (np.dot(weights, X[i]) + bias) <= 0:\n",
        "                # Update weights and bias for a misclassified example\n",
        "                weights += y[i] * X[i]\n",
        "                bias += y[i]\n",
        "            # Accumulate weights and bias for averaging\n",
        "            sum_weights += weights\n",
        "            sum_bias += bias\n",
        "\n",
        "    # Calculation of Average weights and bias over all updates\n",
        "    avg_weights = sum_weights / (sample_count * num_epochs)\n",
        "    avg_bias = sum_bias / (sample_count * num_epochs)\n",
        "    return avg_weights, avg_bias\n",
        "\n",
        "# Train our model on the given dataset\n",
        "avg_weights, avg_bias = train_avg_perceptron(X_train, y_train, num_epochs=10)\n",
        "\n",
        "# Function to make predictions based on weights and bias\n",
        "def predict(X, weights, bias):\n",
        "    return np.sign(np.dot(X, weights) + bias)\n",
        "\n",
        "# Check the model on the test dataset\n",
        "predicted_y = predict(X_test, avg_weights, avg_bias)\n",
        "test_error_rate = np.mean(predicted_y != y_test)\n",
        "\n",
        "# Display the final averaged weight vector and test error rate according to the question\n",
        "print(\"Final averaged weight vector:\", avg_weights)\n",
        "print(\"Test Error Rate:\", test_error_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLelCS6nZNgv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}